{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGBw1OqXar7w"
      },
      "source": [
        "# HIV-Inhibiting Molecule Classification using Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPSnKgqQar7x"
      },
      "source": [
        "## Install Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zd4IVOXar7x"
      },
      "source": [
        "We are going to use Google Colab for this tutorial, since we really need GPU access. To do this:\n",
        "1. Go to https://colab.research.google.com/ (and make sure you are logged in with your Google account)\n",
        "2. Click on \"Github\" and then enter the URL of this repository: https://github.com/AppliedMachineLearningNBI/AppliedML2025\n",
        "3. Scroll down to the \"Week3\" folder and open the \"GNN_HIV_Classification.ipynb\" notebook\n",
        "4. In the top toolbar, click on \"Runtime\"\n",
        "5. Click on \"Change runtime type\"\n",
        "6. Select \"GPU\" from the dropdown menu, and click \"Save\"\n",
        "7. Run the below line of code inside a notebook cell to get the code and data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QlSY2AY_ar7y",
        "outputId": "8eb3a485-8250-4277-b7c0-3c09665dcf0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AppliedML2025'...\n",
            "remote: Enumerating objects: 252, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 252 (delta 43), reused 26 (delta 23), pack-reused 189 (from 2)\u001b[K\n",
            "Receiving objects: 100% (252/252), 47.77 MiB | 10.83 MiB/s, done.\n",
            "Resolving deltas: 100% (70/70), done.\n",
            "Updating files: 100% (128/128), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf AppliedMachineLearningNBI\n",
        "!git clone https://github.com/AppliedMachineLearningNBI/AppliedML2025.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAny6sXsar7y"
      },
      "source": [
        "Once you've done that, let's install the necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-hBM7yoaar7y",
        "outputId": "ae00d8a3-5a19-40f6-a753-e27bf28fca34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl (908.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.20.1\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.1) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.1) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1) (3.0.2)\n",
            "Installing collected packages: triton, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-2.5.1+cu124 torchaudio-2.5.1+cu124 torchvision-0.20.1+cu124 triton-3.1.0\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r AppliedML2025/Week3/requirements.txt (line 18)) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r AppliedML2025/Week3/requirements.txt (line 19)) (1.15.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r AppliedML2025/Week3/requirements.txt (line 20)) (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r AppliedML2025/Week3/requirements.txt (line 21)) (2.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from -r AppliedML2025/Week3/requirements.txt (line 22)) (3.13.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r AppliedML2025/Week3/requirements.txt (line 23)) (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (from -r AppliedML2025/Week3/requirements.txt (line 24)) (2.1.4)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (from -r AppliedML2025/Week3/requirements.txt (line 25)) (4.5.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r AppliedML2025/Week3/requirements.txt (line 26)) (0.13.2)\n",
            "Collecting torch-geometric (from -r AppliedML2025/Week3/requirements.txt (line 27))\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lightning (from -r AppliedML2025/Week3/requirements.txt (line 28))\n",
            "  Downloading lightning-2.5.1.post0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from -r AppliedML2025/Week3/requirements.txt (line 29)) (2.18.0)\n",
            "Collecting ogb (from -r AppliedML2025/Week3/requirements.txt (line 30))\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r AppliedML2025/Week3/requirements.txt (line 20)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r AppliedML2025/Week3/requirements.txt (line 20)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r AppliedML2025/Week3/requirements.txt (line 20)) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r AppliedML2025/Week3/requirements.txt (line 20)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r AppliedML2025/Week3/requirements.txt (line 20)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r AppliedML2025/Week3/requirements.txt (line 20)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r AppliedML2025/Week3/requirements.txt (line 20)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r AppliedML2025/Week3/requirements.txt (line 20)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r AppliedML2025/Week3/requirements.txt (line 21)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r AppliedML2025/Week3/requirements.txt (line 21)) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r AppliedML2025/Week3/requirements.txt (line 23)) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r AppliedML2025/Week3/requirements.txt (line 23)) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost->-r AppliedML2025/Week3/requirements.txt (line 24)) (2.21.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r AppliedML2025/Week3/requirements.txt (line 27)) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r AppliedML2025/Week3/requirements.txt (line 27)) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r AppliedML2025/Week3/requirements.txt (line 27)) (3.1.6)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r AppliedML2025/Week3/requirements.txt (line 27)) (5.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r AppliedML2025/Week3/requirements.txt (line 27)) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric->-r AppliedML2025/Week3/requirements.txt (line 27)) (4.67.1)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (6.0.2)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning->-r AppliedML2025/Week3/requirements.txt (line 28))\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (2.5.1+cu124)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning->-r AppliedML2025/Week3/requirements.txt (line 28))\n",
            "  Downloading torchmetrics-1.7.2-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (4.13.2)\n",
            "Collecting pytorch-lightning (from lightning->-r AppliedML2025/Week3/requirements.txt (line 28))\n",
            "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r AppliedML2025/Week3/requirements.txt (line 29)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r AppliedML2025/Week3/requirements.txt (line 29)) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r AppliedML2025/Week3/requirements.txt (line 29)) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r AppliedML2025/Week3/requirements.txt (line 29)) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r AppliedML2025/Week3/requirements.txt (line 29)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r AppliedML2025/Week3/requirements.txt (line 29)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r AppliedML2025/Week3/requirements.txt (line 29)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->-r AppliedML2025/Week3/requirements.txt (line 29)) (3.1.3)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb->-r AppliedML2025/Week3/requirements.txt (line 30)) (2.4.0)\n",
            "Collecting outdated>=0.2.0 (from ogb->-r AppliedML2025/Week3/requirements.txt (line 30))\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r AppliedML2025/Week3/requirements.txt (line 27)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r AppliedML2025/Week3/requirements.txt (line 27)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r AppliedML2025/Week3/requirements.txt (line 27)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r AppliedML2025/Week3/requirements.txt (line 27)) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r AppliedML2025/Week3/requirements.txt (line 27)) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r AppliedML2025/Week3/requirements.txt (line 27)) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric->-r AppliedML2025/Week3/requirements.txt (line 27)) (1.20.0)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb->-r AppliedML2025/Week3/requirements.txt (line 30))\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning->-r AppliedML2025/Week3/requirements.txt (line 28)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->-r AppliedML2025/Week3/requirements.txt (line 29)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->-r AppliedML2025/Week3/requirements.txt (line 27)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->-r AppliedML2025/Week3/requirements.txt (line 27)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric->-r AppliedML2025/Week3/requirements.txt (line 27)) (2025.4.26)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.1.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading torchmetrics-1.7.2-py3-none-any.whl (962 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.5/962.5 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: littleutils, lightning-utilities, outdated, torch-geometric, torchmetrics, ogb, pytorch-lightning, lightning\n",
            "Successfully installed lightning-2.5.1.post0 lightning-utilities-0.14.3 littleutils-0.2.4 ogb-1.3.6 outdated-0.2.2 pytorch-lightning-2.5.1.post0 torch-geometric-2.6.1 torchmetrics-1.7.2\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.5.0+cu124.html\n",
            "Collecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_scatter-2.1.2%2Bpt25cu124-cp311-cp311-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m128.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_scatter\n",
            "Successfully installed torch_scatter-2.1.2+pt25cu124\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install -r AppliedML2025/Week3/requirements.txt\n",
        "!pip install torch_scatter -f https://data.pyg.org/whl/torch-2.5.0+cu124.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ly0IBNTfar7z"
      },
      "source": [
        "## Intro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-BpcUqIar7z"
      },
      "source": [
        "We are going to learn to classify molecules as either HIV-inhibitors (a useful drug) or not. You can handle a molecule in many different ways - as a list of atoms (like a word/sentence), as a set, or as a graph complete with connections between atoms representing chemical bonds. We will try to treat them as a set and a graph, and see how well we do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWKEc6u-ar7z"
      },
      "source": [
        "The nodes in the graph have features given by `graph.x`:\n",
        "- atomic_num: the atomic number of the atom\n",
        "- chirality: the chirality of the atom\n",
        "- degree: the degree of the atom\n",
        "- formal_charge: the formal charge of the atom\n",
        "- num_h: the number of hydrogens of the atom\n",
        "- num_rad_e: the number of radical electrons of the atom\n",
        "- hybridization: the hybridization of the atom\n",
        "- is_aromatic: whether the atom is aromatic\n",
        "- is_in_ring: whether the atom is in a ring\n",
        "\n",
        "The edges in the graph have features given by `graph.edge_attr`:\n",
        "- bond_type: the type of the bond\n",
        "- bond_stereo: the stereo of the bond\n",
        "- is_conjugated: whether the bond is conjugated\n",
        "\n",
        "The graph has just one \"feature\", which is a binary label indicating whether the molecule is an HIV-inhibitor or not:\n",
        "- `graph.y`: whether the molecule is an HIV-inhibitor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSZaAWYYar7z"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suy9INv0ar7z"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nl8ulquar7z"
      },
      "outputs": [],
      "source": [
        "from ogb.graphproppred import PygGraphPropPredDataset\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "dataset = PygGraphPropPredDataset(name = \"ogbg-molhiv\")\n",
        "\n",
        "split_idx = dataset.get_idx_split()\n",
        "train_pyg_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=32, shuffle=True)\n",
        "valid_pyg_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=32, shuffle=False)\n",
        "test_pyg_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SNR_s1_ar7z"
      },
      "source": [
        "## Visualize the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr19fZUdar70"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjrXdUu3ar70"
      },
      "outputs": [],
      "source": [
        "example_graph = valid_pyg_loader.dataset[0]\n",
        "print(example_graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HVpXemAar70"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gS_n_TiTar70"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Function to visualize graph based on target value\n",
        "def visualize_graph_with_target(loader, target_value):\n",
        "    for graph in loader.dataset:\n",
        "        if graph.y.item() == target_value:\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            atomic_number = graph.x[:, 0].numpy()\n",
        "            graph_networkx = to_networkx(graph.clone())\n",
        "            pos = nx.spring_layout(graph_networkx)\n",
        "            nx.draw_networkx(graph_networkx, pos, labels=dict(zip(range(len(atomic_number)), atomic_number)), node_size=300, node_color=atomic_number, cmap=\"tab20\")\n",
        "            plt.title(f\"Graph with target {graph.y.item()}\")\n",
        "            plt.show()\n",
        "            break\n",
        "\n",
        "# Visualize graph with target 0\n",
        "visualize_graph_with_target(valid_pyg_loader, 0)\n",
        "\n",
        "# Visualize graph with target 1\n",
        "visualize_graph_with_target(valid_pyg_loader, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Z9n2FmJar70"
      },
      "outputs": [],
      "source": [
        "# Plot histograms of graph sizes for true and false graphs\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "def plot_histograms_of_graph_sizes(loader):\n",
        "    true_sizes = []\n",
        "    false_sizes = []\n",
        "    for graph in loader.dataset:\n",
        "        if graph.y.item() == 1:\n",
        "            true_sizes.append(graph.num_nodes)\n",
        "        else:\n",
        "            false_sizes.append(graph.num_nodes)\n",
        "\n",
        "    # Create a DataFrame to facilitate plotting with seaborn\n",
        "    data_true = pd.DataFrame({'Size': true_sizes, 'Target': 'True'})\n",
        "    data_false = pd.DataFrame({'Size': false_sizes, 'Target': 'False'})\n",
        "    data = pd.concat([data_true, data_false])\n",
        "\n",
        "    # Plotting the histograms\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(data, x='Size', hue='Target', element='step', kde=True, palette=['green', 'red'])\n",
        "    plt.title('Histogram of Graph Sizes for True and False Targets')\n",
        "    plt.xlabel('Graph Size')\n",
        "    plt.ylabel('Count')\n",
        "    plt.show()\n",
        "\n",
        "plot_histograms_of_graph_sizes(valid_pyg_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7sg6k15ar70"
      },
      "source": [
        "We see that the data is VERY imbalanced - most molecules are not useful for fighting HIV (as you might expect!). So we will need to be careful about how we evaluate our models. We can't simply use accuracy, as a model that always predicts \"not an HIV-inhibitor\" would be right 99% of the time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o05ET6UEar70"
      },
      "outputs": [],
      "source": [
        "# Let's also histogram each of the node features, so we know what scales they are:\n",
        "def plot_histograms_of_node_features(loader):\n",
        "    feature_names = ['atomic_num', 'chirality', 'degree', 'formal_charge', 'num_h', 'num_rad_e', 'hybridization', 'is_aromatic', 'is_in_ring']\n",
        "    num_features = len(feature_names)\n",
        "\n",
        "    # Create a 3x3 subplot grid\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
        "    axes = axes.flatten()  # Flatten the 2D array of axes to 1D for easier iteration\n",
        "\n",
        "    for i in range(num_features):\n",
        "        all_features = []\n",
        "        for graph in loader.dataset:\n",
        "            all_features.extend(graph.x[:, i].numpy())\n",
        "\n",
        "        # Plot on the ith subplot\n",
        "        sns.histplot(all_features, element='step', ax=axes[i])\n",
        "        axes[i].set_title(f'Histogram of {feature_names[i]}')\n",
        "        axes[i].set_xlabel(f'{feature_names[i]} Value')\n",
        "        axes[i].set_ylabel('Count')\n",
        "        axes[i].set_yscale('log')  # Set y-axis scale to logarithmic\n",
        "\n",
        "    # Adjust layout to prevent overlap\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_histograms_of_node_features(valid_pyg_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyiZXePcar70"
      },
      "source": [
        "Overall, the data is all of a similar scale, so we don't need to be too worried about normalizing. Maybe we could take the log of the atomic number, and add that as a feature. But that's about it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-JrsyBBar70"
      },
      "source": [
        "## Try Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLSoGknkar71"
      },
      "source": [
        "Let's try the absolute most naive thing: Logistic regression. This will give us a baseline to compare against.\n",
        "The first question is what is the input to our logistic regression. It's non-obvious, since we have two problems:\n",
        "1. The input features are nodes in no obvious or particular order\n",
        "2. The list of nodes is different from one graph to the next\n",
        "\n",
        "So to make our first naive benchmark as simple as possible, let's take some simplifications to the dataset:\n",
        "1. Let's sort the nodes from largest to smallest atomic number\n",
        "2. Let's take the first 10 sorted nodes in each graph, and pad with zeros if there are fewer than 20 nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cp3Z2Cvar71"
      },
      "source": [
        "### Sort the nodes by atomic number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpB17kvrar71"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
        "\n",
        "# Function to preprocess and flatten graph data\n",
        "def preprocess_data(loader):\n",
        "    X, y = [], []\n",
        "    for data in loader.dataset:\n",
        "        # Sort nodes by atomic number in descending order\n",
        "        node_features = data.x\n",
        "        sorted_nodes = node_features[node_features[:, 0].argsort(descending=True)]\n",
        "\n",
        "        # Add log of the first feature (atomic number) as a new feature\n",
        "        log_feature = np.log(sorted_nodes[:, 0] + 1).reshape(-1, 1)  # Adding 1 to avoid log(0)\n",
        "        sorted_nodes = np.hstack([sorted_nodes, log_feature])\n",
        "\n",
        "        # Select the first N nodes\n",
        "        num_nodes = 20\n",
        "\n",
        "        # Select the first 20 nodes, pad if necessary\n",
        "        if len(sorted_nodes) < num_nodes:\n",
        "            padding = np.zeros((num_nodes - len(sorted_nodes), sorted_nodes.shape[1]))\n",
        "            sorted_nodes = np.vstack([sorted_nodes, padding])\n",
        "        elif len(sorted_nodes) > num_nodes:\n",
        "            sorted_nodes = sorted_nodes[:num_nodes]\n",
        "\n",
        "        # Flatten the node features to create a single feature vector\n",
        "        flat_features = sorted_nodes.flatten()\n",
        "        X.append(flat_features)\n",
        "        y.append(data.y.item())\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eH0phwSKar71"
      },
      "outputs": [],
      "source": [
        "# Preprocess the data\n",
        "X_train, y_train = preprocess_data(train_pyg_loader)\n",
        "X_valid, y_valid = preprocess_data(valid_pyg_loader)\n",
        "X_test, y_test = preprocess_data(test_pyg_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KU5fAcH0ar71"
      },
      "outputs": [],
      "source": [
        "# Train logistic regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_valid = model.predict(X_valid)\n",
        "y_pred_test = model.predict(X_test)\n",
        "valid_accuracy = accuracy_score(y_valid, y_pred_valid)\n",
        "valid_auc = roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1])\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "test_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "\n",
        "print(f\"Validation Accuracy: {valid_accuracy}\")\n",
        "print(f\"Validation AUC: {valid_auc}\")\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "print(f\"Test AUC: {test_auc}\")\n",
        "\n",
        "# Also get the ROC AUC for a random classifier\n",
        "random_preds = np.random.rand(len(y_test))\n",
        "random_auc = roc_auc_score(y_test, random_preds)\n",
        "\n",
        "fpr_valid, tpr_valid, _ = roc_curve(y_valid, model.predict_proba(X_valid)[:, 1])\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr_valid, tpr_valid, label='Validation')\n",
        "plt.plot(fpr_test, tpr_test, label='Test')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='black')\n",
        "plt.text(0.7, 0.3, f'Valid AUC: {valid_auc:.2f}', fontsize=12)\n",
        "plt.text(0.7, 0.2, f'Test AUC: {test_auc:.2f}', fontsize=12)\n",
        "plt.text(0.7, 0.1, f'Random AUC: {random_auc:.2f}', fontsize=12)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Logistic Regression')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEFKx4C9ar71"
      },
      "source": [
        "Okay, we're better than a coin flip. Not bad for 3 seconds of work. But we have a long way to go if we want to get onto the OGB Leaderboard for this benchmark:\n",
        "![OGB Leaderboard](https://github.com/AppliedMachineLearningNBI/AppliedML2025/blob/main/Week3/img/ogb-leaderboard.jpg?raw=1)\n",
        "\n",
        "\n",
        "\n",
        "So let's try something more sophisticated...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zAyYR7War71"
      },
      "source": [
        "## Try a BDT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVlc3DYhar71"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Train Gradient Boosting model\n",
        "bdt_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "bdt_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model using AUC\n",
        "y_prob_valid_bdt = bdt_model.predict_proba(X_valid)[:, 1]  # Get probabilities for the positive class\n",
        "y_prob_test_bdt = bdt_model.predict_proba(X_test)[:, 1]    # Get probabilities for the positive class\n",
        "\n",
        "valid_auc_bdt = roc_auc_score(y_valid, y_prob_valid_bdt)\n",
        "test_auc_bdt = roc_auc_score(y_test, y_prob_test_bdt)\n",
        "\n",
        "print(f\"Validation AUC (BDT): {valid_auc_bdt}\")\n",
        "print(f\"Test AUC (BDT): {test_auc_bdt}\")\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr_valid_bdt, tpr_valid_bdt, _ = roc_curve(y_valid, y_prob_valid_bdt)\n",
        "fpr_test_bdt, tpr_test_bdt, _ = roc_curve(y_test, y_prob_test_bdt)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr_valid_bdt, tpr_valid_bdt, label='Validation (BDT)')\n",
        "plt.plot(fpr_test_bdt, tpr_test_bdt, label='Test (BDT)')\n",
        "plt.plot(fpr_valid, tpr_valid, label='Validation (LR)')\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='black')\n",
        "plt.text(0.7, 0.3, f'Validation AUC (BDT): {valid_auc_bdt:.2f}', fontsize=12)\n",
        "plt.text(0.7, 0.2, f'Test AUC (BDT): {test_auc_bdt:.2f}', fontsize=12)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDU80hiuar71"
      },
      "source": [
        "Creeping up... but still a long way to go to an AUC of 0.84. Let's try a simple neural network next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XURvvTlKar72"
      },
      "source": [
        "## Try a simple neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tlfPuVRar72"
      },
      "source": [
        "For this simple neural network, let's switch back to pytorch. In particular, let's use pytorch lightning to avoid boilerplate code. (If you haven't used pytorch or pytorch lightning before, you can think of pytorch = tensorboard, and pytorch lightning = keras)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jC7FerQsar72"
      },
      "outputs": [],
      "source": [
        "import lightning as lit\n",
        "from lightning.pytorch.callbacks import Callback\n",
        "from lightning.pytorch import Trainer\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "from torch import nn\n",
        "from lightning.pytorch.loggers import CSVLogger  # Import CSVLogger\n",
        "import numpy as np\n",
        "\n",
        "def prepare_data_loaders(X_train, y_train, X_valid, y_valid, X_test, y_test, batch_size=32):\n",
        "    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
        "    valid_dataset = TensorDataset(torch.FloatTensor(X_valid), torch.FloatTensor(y_valid))\n",
        "    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, valid_loader, test_loader\n",
        "\n",
        "def make_mlp(\n",
        "    input_size,\n",
        "    sizes,\n",
        "    hidden_activation=\"ReLU\",\n",
        "    output_activation=None,\n",
        "    layer_norm=False,\n",
        "):\n",
        "    \"\"\"Construct an MLP with specified fully-connected layers.\"\"\"\n",
        "    hidden_activation = getattr(nn, hidden_activation)()\n",
        "    output_activation = getattr(nn, output_activation)() if output_activation else None\n",
        "    layers = []\n",
        "    sizes = [input_size] + sizes\n",
        "\n",
        "    # Add hidden layers\n",
        "    for i in range(len(sizes) - 2):  # Change the range to stop before the last hidden layer\n",
        "        layers.append(nn.Linear(sizes[i], sizes[i + 1]))\n",
        "        if layer_norm:\n",
        "            layers.append(nn.LayerNorm(sizes[i + 1], elementwise_affine=False))\n",
        "        layers.append(hidden_activation)\n",
        "\n",
        "    # Add final layer\n",
        "    layers.append(nn.Linear(sizes[-2], sizes[-1]))\n",
        "    if output_activation:\n",
        "        layers.append(output_activation)\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class BaseLitModel(lit.LightningModule):\n",
        "    def __init__(self, lr=1e-3, weight_decay=0, lr_decay=0.95):\n",
        "        super().__init__()\n",
        "\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.val_preds = []\n",
        "        self.val_targets = []\n",
        "        self.test_preds = []\n",
        "        self.test_targets = []\n",
        "        self.lr = lr\n",
        "        self.weight_decay = weight_decay\n",
        "        self.lr_decay = lr_decay\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        y_hat, y = self.apply_model(batch)\n",
        "        # Check if y needs to be unsqueezed\n",
        "        if len(y.shape) == 1:\n",
        "            y = y.unsqueeze(1)\n",
        "        loss = self.criterion(y_hat, y.float())\n",
        "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)  # Log on progress bar\n",
        "        self.log('learning_rate', self.trainer.optimizers[0].param_groups[0]['lr'], on_step=False, on_epoch=True, prog_bar=True)  # Log current learning rate\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        y_hat, y = self.apply_model(batch)\n",
        "        # Check if y needs to be unsqueezed\n",
        "        if len(y.shape) == 1:\n",
        "            y = y.unsqueeze(1)\n",
        "        loss = self.criterion(y_hat, y.float())\n",
        "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)  # Log on progress bar\n",
        "        self.val_preds.extend(y_hat.view(-1).detach().cpu().numpy())\n",
        "        self.val_targets.extend(y.view(-1).detach().cpu().numpy())\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        y_hat, y = self.apply_model(batch)\n",
        "        # Check if y needs to be unsqueezed\n",
        "        if len(y.shape) == 1:\n",
        "            y = y.unsqueeze(1)\n",
        "        loss = self.criterion(y_hat, y.float())\n",
        "        self.log('test_loss', loss, on_epoch=True, prog_bar=True)  # Log on progress bar\n",
        "        self.test_preds.extend(y_hat.view(-1).detach().cpu().numpy())\n",
        "        self.test_targets.extend(y.view(-1).detach().cpu().numpy())\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
        "        lr_scheduler = {\n",
        "            'scheduler': torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: self.lr_decay ** epoch),\n",
        "            'name': 'lambda_decay'\n",
        "        }\n",
        "        return [optimizer], [lr_scheduler]\n",
        "\n",
        "class AUCCallback(Callback):\n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        val_auc = roc_auc_score(pl_module.val_targets, pl_module.val_preds)\n",
        "        pl_module.log(\"val_auc\", val_auc, prog_bar=True)  # Log on progress bar\n",
        "        pl_module.val_preds = []\n",
        "        pl_module.val_targets = []\n",
        "\n",
        "    def on_test_epoch_end(self, trainer, pl_module):\n",
        "        test_auc = roc_auc_score(pl_module.test_targets, pl_module.test_preds)\n",
        "        pl_module.log(\"test_auc\", test_auc, prog_bar=True)  # Log on progress bar\n",
        "        pl_module.test_preds = []\n",
        "        pl_module.test_targets = []\n",
        "\n",
        "# Prepare data loaders\n",
        "def prepare_data_loaders(X_train, y_train, X_valid, y_valid, X_test, y_test, batch_size=32):\n",
        "    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
        "    valid_dataset = TensorDataset(torch.FloatTensor(X_valid), torch.FloatTensor(y_valid))\n",
        "    test_dataset = TensorDataset(torch.FloatTensor(X_test), torch.FloatTensor(y_test))\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, valid_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oto_ePvVar72"
      },
      "outputs": [],
      "source": [
        "class SimpleMLP(BaseLitModel):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleMLP, self).__init__(lr=1e-3, weight_decay=0, lr_decay=0.90)\n",
        "        self.model = make_mlp(input_size,\n",
        "                              [hidden_size]*3 + [output_size],\n",
        "                              hidden_activation=\"ReLU\",\n",
        "                              layer_norm=True,\n",
        "                              output_activation=\"Sigmoid\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def apply_model(self, batch):\n",
        "        x, y = batch\n",
        "        return self(x), y\n",
        "\n",
        "# Data loaders\n",
        "train_loader, valid_loader, test_loader = prepare_data_loaders(X_train, y_train, X_valid, y_valid, X_test, y_test)\n",
        "\n",
        "# Initialize the model\n",
        "input_size = train_loader.dataset[0][0].shape[0]  # Adjust input size for the new feature\n",
        "hidden_size = 64  # You can tune this parameter\n",
        "output_size = 1\n",
        "model = SimpleMLP(input_size, hidden_size, output_size)\n",
        "\n",
        "# Train the model\n",
        "auc_callback = AUCCallback()\n",
        "csv_logger = CSVLogger('lightning_logs', name='mlp_model')  # Initialize CSVLogger\n",
        "trainer = Trainer(max_epochs=10, accelerator=\"gpu\", callbacks=[auc_callback], logger=csv_logger)  # Add logger to Trainer\n",
        "trainer.fit(model, train_loader, valid_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGQLanjXar72"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def find_latest_directory(base_path):\n",
        "    list_of_files = glob.glob(f'{base_path}/version_*')\n",
        "    latest_dir = max(list_of_files, key=os.path.getmtime)\n",
        "    return latest_dir\n",
        "\n",
        "def plot_metrics(directory, model_name):\n",
        "    metrics_file = os.path.join(directory, 'metrics.csv')\n",
        "    metrics_df = pd.read_csv(metrics_file)\n",
        "    train_loss_df = metrics_df[metrics_df['train_loss'].notna()]\n",
        "    val_loss_df = metrics_df[metrics_df['val_loss'].notna()]\n",
        "    val_auc_df = metrics_df[metrics_df['val_auc'].notna()]\n",
        "    learning_rate_df = metrics_df[metrics_df['learning_rate'].notna()]  # Extract learning rate data\n",
        "\n",
        "    plt.figure(figsize=(16, 4))  # Adjusted figure size to accommodate new subplot\n",
        "    plt.subplot(1, 4, 1)\n",
        "    plt.plot(train_loss_df['step'], train_loss_df['train_loss'], label='Training Loss')\n",
        "    plt.title('Training Loss Over Epochs')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xscale('log')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 4, 2)\n",
        "    plt.plot(val_loss_df['epoch'], val_loss_df['val_loss'], label='Validation Loss')\n",
        "    plt.title('Validation Loss Over Epochs')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xscale('log')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 4, 3)\n",
        "    plt.plot(val_auc_df['epoch'], val_auc_df['val_auc'], label='Validation AUC')\n",
        "    plt.title('Validation AUC Over Epochs')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.xscale('log')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 4, 4)\n",
        "    plt.plot(learning_rate_df['epoch'], learning_rate_df['learning_rate'], label='Learning Rate')\n",
        "    plt.title('Learning Rate Over Epochs')\n",
        "    plt.xlabel('Step')\n",
        "    plt.ylabel('Learning Rate')\n",
        "    plt.xscale('log')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1_tq60xar73"
      },
      "outputs": [],
      "source": [
        "base_path = 'lightning_logs/mlp_model'\n",
        "latest_dir = find_latest_directory(base_path)\n",
        "plot_metrics(latest_dir, 'MLP Model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmMuFR47ar73"
      },
      "source": [
        "## Interaction Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TDYU2rHar73"
      },
      "source": [
        "So we're struggling to beat the BDT - it's just too good at consuming tabular data. But we have a secret weapon: the graph structure! Let's try a simple graph convolution network. We will use the industry-standard PyG (\"Pytorch Geometric\") library for this, with its built-in GCN implementation. But first, let's try to code up a graph neural network from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkZDx1b3ar73"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_scatter import scatter_mean, scatter_add\n",
        "from torch import nn\n",
        "\n",
        "class InteractionGNN(BaseLitModel):\n",
        "    def __init__(self, hparams):\n",
        "        super(InteractionGNN, self).__init__(lr=hparams['lr'], weight_decay=hparams['weight_decay'], lr_decay=hparams['lr_decay'])\n",
        "\n",
        "        # Node and Edge Networks\n",
        "        self.input_node_network = make_mlp(\n",
        "            input_size=hparams['input_size'],\n",
        "            sizes=[hparams['hidden_size']] * 2,\n",
        "            layer_norm=True,\n",
        "            hidden_activation=\"ReLU\"\n",
        "        )\n",
        "        self.node_network = make_mlp(\n",
        "            input_size=hparams['hidden_size'],\n",
        "            sizes=[hparams['hidden_size']] * 2,\n",
        "            layer_norm=True,\n",
        "            hidden_activation=\"ReLU\"\n",
        "        )\n",
        "        self.edge_network = make_mlp(\n",
        "            input_size=2 * hparams['hidden_size'],\n",
        "            sizes=[hparams['hidden_size']] * 2,\n",
        "            layer_norm=True,\n",
        "            hidden_activation=\"ReLU\"\n",
        "        )\n",
        "        self.output_network = make_mlp(\n",
        "            input_size=hparams['hidden_size'],\n",
        "            sizes=[hparams['output_size']],\n",
        "            layer_norm=True,\n",
        "            hidden_activation=\"ReLU\",\n",
        "            output_activation=\"Sigmoid\"\n",
        "        )\n",
        "        self.num_graph_iters = hparams['num_graph_iters']\n",
        "\n",
        "        self.aggregation = scatter_add\n",
        "\n",
        "    def forward(self, graph):\n",
        "        x, edge_index = graph.x.float(), graph.edge_index\n",
        "        start, end = edge_index\n",
        "        x = self.input_node_network(x)\n",
        "\n",
        "        for _ in range(self.num_graph_iters):\n",
        "            # Save the input to the iteration for the skip connection\n",
        "            x_skip = x\n",
        "\n",
        "            # Edge features update\n",
        "            e = self.message_passing(x, start, end)\n",
        "\n",
        "            # Message passing\n",
        "            x = self.aggregation(e, end, dim=0, dim_size=x.size(0))  # Aggregating messages to target nodes\n",
        "\n",
        "            # Node features update\n",
        "            x = self.node_network(x)\n",
        "\n",
        "            # Adding skip connection\n",
        "            x = x + x_skip\n",
        "\n",
        "        # Aggregate to graph level\n",
        "        x = self.aggregation(x, graph.batch, dim=0)\n",
        "\n",
        "        # Output layer\n",
        "        out = self.output_network(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def message_passing(self, x, start, end):\n",
        "\n",
        "        edge_features = torch.cat([x[start], x[end]], dim=1)\n",
        "        e = self.edge_network(edge_features)\n",
        "        return e\n",
        "\n",
        "    def apply_model(self, batch):\n",
        "        return self(batch), batch.y\n",
        "\n",
        "# Example usage\n",
        "hparams = {\n",
        "    'input_size': train_pyg_loader.dataset[0].x.shape[1],\n",
        "    'hidden_size': 64,\n",
        "    'output_size': 1,\n",
        "    'lr': 3e-4,\n",
        "    'weight_decay': 1e-5,\n",
        "    'lr_decay': 0.97,\n",
        "    'num_graph_iters': 3  # Number of graph iterations\n",
        "}\n",
        "model = InteractionGNN(hparams)\n",
        "\n",
        "# Training setup remains the same\n",
        "auc_callback = AUCCallback()\n",
        "csv_logger = CSVLogger('lightning_logs', name='interaction_gnn_model')\n",
        "trainer = Trainer(max_epochs=50, accelerator=\"gpu\", callbacks=[auc_callback], logger=csv_logger)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBYH1aAXar74"
      },
      "outputs": [],
      "source": [
        "trainer.fit(model, train_pyg_loader, valid_pyg_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmxV5zg_ar74"
      },
      "outputs": [],
      "source": [
        "base_path = 'lightning_logs/interaction_gnn_model'\n",
        "latest_dir = find_latest_directory(base_path)\n",
        "plot_metrics(latest_dir, 'Interaction GNN Model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kK6jI_Gfar74"
      },
      "outputs": [],
      "source": [
        "# Test the model\n",
        "trainer.test(model, test_pyg_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3n1RqRWar75"
      },
      "outputs": [],
      "source": [
        "from ogb.graphproppred import Evaluator\n",
        "\n",
        "evaluator = Evaluator(name = 'ogbg-molhiv')\n",
        "\n",
        "y_true = torch.cat([graph.y for graph in valid_pyg_loader]).numpy()\n",
        "with torch.no_grad():\n",
        "    y_pred = torch.cat([model(graph) for graph in valid_pyg_loader]).numpy()\n",
        "input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
        "result_dict = evaluator.eval(input_dict)\n",
        "print(\"VALIDATION RESULTS\", result_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfvLCuiVar75"
      },
      "outputs": [],
      "source": [
        "from ogb.graphproppred import Evaluator\n",
        "\n",
        "evaluator = Evaluator(name = 'ogbg-molhiv')\n",
        "\n",
        "y_true = torch.cat([graph.y for graph in test_pyg_loader]).numpy()\n",
        "with torch.no_grad():\n",
        "    y_pred = torch.cat([model(graph) for graph in test_pyg_loader]).numpy()\n",
        "input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
        "result_dict = evaluator.eval(input_dict)\n",
        "print(\"TEST RESULTS\", result_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKTYweI3ar75"
      },
      "source": [
        "# Try your own Torch Geometric model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIdLV4l_ar75"
      },
      "source": [
        "## Play with convolution and aggregation styles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj435r0var75"
      },
      "source": [
        "We can tweak the convolution and aggregation styles to see if we can improve the performance of our model. E.g. we can try scatter max, scatter std, combine scatter operations, or we can try the MANY different convolutions available in PyG."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcaqM4rgar75"
      },
      "source": [
        "## We can also try out-of-the-box convolutions from Pytorch Geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WyfevRtar75"
      },
      "source": [
        "### Try a simple graph convolution network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90F_Jl-Var75"
      },
      "outputs": [],
      "source": [
        "import lightning as lit\n",
        "from lightning.pytorch.callbacks import Callback\n",
        "from lightning.pytorch import Trainer\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch_geometric.nn import GCNConv, aggr\n",
        "from lightning.pytorch.loggers import CSVLogger  # Import CSVLogger\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
        "\n",
        "class GCN(BaseLitModel):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(GCN, self).__init__(lr=1e-3, weight_decay=0, lr_decay=0.90)\n",
        "        self.node_network_1 = make_mlp(input_size, [hidden_size]*2, layer_norm=True, hidden_activation=\"ReLU\")\n",
        "        self.conv = GCNConv(hidden_size, hidden_size)\n",
        "        self.node_network_2 = make_mlp(hidden_size, [hidden_size]*2, layer_norm=True, hidden_activation=\"ReLU\")\n",
        "        self.output_network = make_mlp(hidden_size, [output_size], layer_norm=True, hidden_activation=\"ReLU\", output_activation=\"Sigmoid\")\n",
        "        self.aggregation = aggr.MeanAggregation()\n",
        "\n",
        "    def forward(self, graph):\n",
        "        x = self.node_network_1(graph.x.float())\n",
        "        x = self.conv(x, graph.edge_index)\n",
        "        x = self.node_network_2(x)\n",
        "        x = self.aggregation(x, graph.batch)\n",
        "        return self.output_network(x)\n",
        "\n",
        "    def apply_model(self, batch):\n",
        "        return self(batch), batch.y\n",
        "\n",
        "# Initialize the model\n",
        "input_size = train_pyg_loader.dataset[0].x.shape[1]\n",
        "hidden_size = 64  # You can tune this parameter\n",
        "output_size = 1\n",
        "model = GCN(input_size, hidden_size, output_size)\n",
        "\n",
        "# Train the model\n",
        "auc_callback = AUCCallback()\n",
        "csv_logger = CSVLogger('lightning_logs', name='gcn_model')  # Initialize CSVLogger\n",
        "trainer = Trainer(max_epochs=10, accelerator=\"gpu\", callbacks=[auc_callback], logger=csv_logger)  # Add logger to Trainer\n",
        "trainer.fit(model, train_pyg_loader, valid_pyg_loader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMnDXBx7ar75"
      },
      "outputs": [],
      "source": [
        "base_path = 'lightning_logs/gcn_model'\n",
        "latest_dir = find_latest_directory(base_path)\n",
        "plot_metrics(latest_dir, 'GCN Model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBAyqTkear75"
      },
      "source": [
        "### Test graph attention network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWBvLxRrar75"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn import GATv2Conv\n",
        "\n",
        "class GAT(BaseLitModel):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(GAT, self).__init__(lr=1e-3, weight_decay=0, lr_decay=0.90)\n",
        "        self.node_network_1 = make_mlp(input_size, [hidden_size]*2, layer_norm=True, hidden_activation=\"ReLU\")\n",
        "        self.conv = GATv2Conv(hidden_size, hidden_size, heads=1)\n",
        "        self.node_network_2 = make_mlp(hidden_size, [hidden_size]*2, layer_norm=True, hidden_activation=\"ReLU\")\n",
        "        self.output_network = make_mlp(hidden_size, [output_size], layer_norm=True, hidden_activation=\"ReLU\", output_activation=\"Sigmoid\")\n",
        "        self.aggregation = aggr.MeanAggregation()\n",
        "\n",
        "    def forward(self, graph):\n",
        "        x = self.node_network_1(graph.x.float())\n",
        "        x = self.conv(x, graph.edge_index)\n",
        "        x = self.node_network_2(x)\n",
        "        x = self.aggregation(x, graph.batch)\n",
        "        return self.output_network(x)\n",
        "\n",
        "    def apply_model(self, batch):\n",
        "        return self(batch), batch.y\n",
        "\n",
        "# Initialize the model\n",
        "input_size = train_pyg_loader.dataset[0].x.shape[1]\n",
        "hidden_size = 64  # You can tune this parameter\n",
        "output_size = 1\n",
        "model = GAT(input_size, hidden_size, output_size)\n",
        "\n",
        "# Train the model\n",
        "auc_callback = AUCCallback()\n",
        "csv_logger = CSVLogger('lightning_logs', name='gat_model')  # Initialize CSVLogger\n",
        "trainer = Trainer(max_epochs=10, accelerator=\"gpu\", callbacks=[auc_callback], logger=csv_logger)  # Add logger to Trainer\n",
        "trainer.fit(model, train_pyg_loader, valid_pyg_loader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHaufHt2ar75"
      },
      "outputs": [],
      "source": [
        "base_path = 'lightning_logs/gat_model'\n",
        "latest_dir = find_latest_directory(base_path)\n",
        "plot_metrics(latest_dir, 'GAT Model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGf0zSAQar76"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bc_lvTjCar76"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}